{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d103a51",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4dcb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paths:\n",
      "  project_root: /home/p84400019/projects/consciousness-llms/IT-LLMs/\n",
      "  model_path: ${model.company}/${model.model_family}/${model.model_size}/${model.it}/\n",
      "  activation_method: ${time_series.node_type}/${time_series.node_activation}/${time_series.projection_method}/\n",
      "  phyid_method: ${paths.activation_method}phyid_tau-${phyid.tau}/phyid_kind-${phyid.kind}/phyid_redundancy-${phyid.redundancy}/\n",
      "  deactivation_method: deactivate_k_nodes_per_iteration-${deactivation_analysis.deactivate_k_nodes_per_iteration}/max_deactivated_nodes-${deactivation_analysis.max_deactivated_nodes}/\n",
      "  data_dir: ${paths.project_root}data/${paths.model_path}${generation.name}/\n",
      "  data_activations_dir: ${paths.data_dir}activations/\n",
      "  data_activations_file: ${paths.data_activations_dir}multi_prompt_activations.pkl\n",
      "  data_phyid_dir: ${paths.data_dir}phyid/${paths.phyid_method}\n",
      "  data_phyid_file: ${paths.data_phyid_dir}multi_prompt_phyid.pkl\n",
      "  data_phyid_file_data_array: ${paths.data_phyid_dir}multi_prompt_phyid.nc\n",
      "  data_deactivation_dir: ${paths.data_dir}deactivation/\n",
      "  data_deactivation_file: ${paths.data_deactivation_dir}ranked/${paths.phyid_method}${paths.deactivation_method}multi_prompt_deactivation.pkl\n",
      "  data_random_deactivation_runs: ${paths.data_deactivation_dir}random/${paths.deactivation_method}\n",
      "  plot_dir: ${paths.project_root}plots/${paths.model_path}${generation.name}/\n",
      "  plot_time_series_dir: ${paths.plot_dir}time_series/${paths.activation_method}\n",
      "  plot_phyid_dir: ${paths.plot_dir}phyid/${paths.phyid_method}\n",
      "  plot_deactivation_dir: ${paths.plot_dir}deactivation/${paths.phyid_method}${paths.deactivation_method}\n",
      "  plot_synergy_through_training_dir: ${paths.plot_dir}synergy_through_training/${paths.phyid_method}\n",
      "model:\n",
      "  shortcode: G3-1\n",
      "  hf_name: google/gemma-3-1b-pt\n",
      "  company: google\n",
      "  model_family: gemma-3\n",
      "  model_size: 1B\n",
      "  it: base\n",
      "  plot_name: Gemma 3 1B Base\n",
      "  color: '#647c00'\n",
      "  apply_chat_template: base\n",
      "generation:\n",
      "  name: base_prompt\n",
      "  max_new_tokens: 128\n",
      "  prompts:\n",
      "    all:\n",
      "    - Imagine a future where humans have evolved to live underwater. Describe the\n",
      "      adaptations they might develop.\n",
      "time_series:\n",
      "  exclude_shared_expert_moe: true\n",
      "  projection_method: norm\n",
      "  node_type: attention\n",
      "  node_activation: attention_outputs\n",
      "phyid:\n",
      "  tau: 1\n",
      "  kind: gaussian\n",
      "  redundancy: MMI\n",
      "deactivation_analysis:\n",
      "  deactivate_k_nodes_per_iteration: 5\n",
      "  max_deactivated_nodes: 100\n",
      "  n_randomised_runs: 5\n",
      "  reverse_kl: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "initialize(config_path=\"../config\", version_base=\"1.3\")\n",
    "cfg = compose(config_name=\"config\")\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "if str(cfg.paths.project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(cfg.paths.project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b7f66",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4ea0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p84400019/miniconda3/envs/int/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gemma3.modeling_gemma3.Gemma3ForCausalLM'>\n",
      "Gemma3ForCausalLM(\n",
      "  (model): Gemma3TextModel(\n",
      "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 1152, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-25): 26 x Gemma3DecoderLayer(\n",
      "        (self_attn): Gemma3Attention(\n",
      "          (q_proj): Linear(in_features=1152, out_features=1024, bias=False)\n",
      "          (k_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1152, bias=False)\n",
      "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Gemma3MLP(\n",
      "          (gate_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
      "          (up_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
      "          (down_proj): Linear(in_features=6912, out_features=1152, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "    (rotary_emb): Gemma3RotaryEmbedding()\n",
      "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1152, out_features=262144, bias=False)\n",
      ")\n",
      "Gemma3TextConfig {\n",
      "  \"architectures\": [\n",
      "    \"Gemma3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attn_logit_softcapping\": null,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"cache_implementation\": \"hybrid\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"final_logit_softcapping\": null,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 1152,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6912,\n",
      "  \"layer_types\": [\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"full_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"full_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"full_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"full_attention\",\n",
      "    \"sliding_attention\",\n",
      "    \"sliding_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"gemma3_text\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 26,\n",
      "  \"num_key_value_heads\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"query_pre_attn_scalar\": 256,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_local_base_freq\": 10000,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": 512,\n",
      "  \"sliding_window_pattern\": 6,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 262144\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, AutoConfig\n",
    "from src.utils import perturb_model, randomize_model_weights\n",
    "\n",
    "load_model = True\n",
    "\n",
    "model_name = cfg.model.hf_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "if load_model:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, \n",
    "        device_map='auto', \n",
    "        attn_implementation='eager',  \n",
    "        trust_remote_code=True,\n",
    "        revision=cfg.model.revision if hasattr(cfg.model, 'revision') else None,\n",
    "    )\n",
    "    if cfg.model.it == 'random':\n",
    "        # randomize_model_weights(model, mean=0.0, std=0.02)\n",
    "        perturb_model(model, scale=10.0)\n",
    "    # model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "    # model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "    model.eval()\n",
    "print(type(model))\n",
    "print(model)\n",
    "print(model.config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62cfd6",
   "metadata": {},
   "source": [
    "### Record activations, save them, and verify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa457a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using prompt_template: base\n",
      "Recorder initialized for model: ModelInformation(model_name='google/gemma-3-1b-pt', model_architecture='Gemma3ForCausalLM', num_layers=26, num_attention_heads_per_layer=4, total_num_attention_heads=104, hidden_size=1152, head_dim=256, n_routed_experts=None, n_shared_experts=None, num_experts_per_tok=None, attention_implementation='default')\n",
      "Working on prompt 0: Question: Imagine a future where humans have evolved to live underwater. Describe the adaptations they might develop.\n",
      " Answer: \n",
      "\n",
      "Prompt 0 completed: Question: Imagine a future where humans have evolved to live underwater. Describe the adaptations they might develop.\n",
      " Answer: 1. Humans might develop gills and gills might evolve, too.\n",
      " 2. They might need to evolve air tanks, also.\n",
      " 3. Many people might die because of lack of oxygen in water.\n",
      "\n",
      "Recorded 1 activations for 1 prompts.\n",
      "MultiPromptActivations successfully saved to '/home/p84400019/projects/consciousness-llms/IT-LLMs/data/google/gemma-3/1B/base/base_prompt/activations/multi_prompt_activations.pkl'.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected 128 steps, got 44",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecorded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(activations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m activations for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m prompts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m activations\u001b[38;5;241m.\u001b[39msave(data_activations_file)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_recorded_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_q_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/consciousness-llms/IT-LLMs/src/activation_recorder/MultiPromptActivations.py:101\u001b[0m, in \u001b[0;36mMultiPromptActivations.verify_recorded_activations\u001b[0;34m(self, prompts, max_new_tokens, tokenizer, diff_q_size)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Check shape of activations\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(activations) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompts), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m prompts, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(activations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(activations\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m==\u001b[39m max_new_tokens, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_new_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m steps, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(activations\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msteps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(activations\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m==\u001b[39m activations\u001b[38;5;241m.\u001b[39mmodel_info\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivations\u001b[38;5;241m.\u001b[39mmodel_info\u001b[38;5;241m.\u001b[39mnum_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(activations\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(activations\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mattention\u001b[38;5;241m.\u001b[39mheads) \u001b[38;5;241m==\u001b[39m activations\u001b[38;5;241m.\u001b[39mmodel_info\u001b[38;5;241m.\u001b[39mnum_attention_heads_per_layer, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivations\u001b[38;5;241m.\u001b[39mmodel_info\u001b[38;5;241m.\u001b[39mnum_attention_heads_per_layer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m heads, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(activations\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mattention\u001b[38;5;241m.\u001b[39mheads)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected 128 steps, got 44"
     ]
    }
   ],
   "source": [
    "from src.activation_recorder import ActivationRecorder, MultiPromptActivations\n",
    "\n",
    "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
    "\n",
    "load_from_disk = False\n",
    "data_activations_file = cfg.paths.data_activations_file\n",
    "max_new_tokens=cfg.generation.max_new_tokens\n",
    "prompts = cfg.generation.prompts\n",
    "# if it not a list but a list of lists, flatten it\n",
    "if isinstance(prompts, list) and all(isinstance(p, list) for p in prompts):\n",
    "    prompts = [item for sublist in prompts for item in sublist]\n",
    "\n",
    "prompt_template = cfg.model.apply_chat_template\n",
    "print(f\"Using prompt_template: {prompt_template}\")\n",
    "\n",
    "if not load_from_disk:\n",
    "    recorder = ActivationRecorder(model, tokenizer)\n",
    "    activations = recorder.record_prompts(prompts, max_new_tokens=max_new_tokens, prompt_template=prompt_template)\n",
    "    print(f\"Recorded {len(activations)} activations for {len(prompts)} prompts.\")\n",
    "    activations.save(data_activations_file)\n",
    "    activations.verify_recorded_activations(prompts=prompts, max_new_tokens=max_new_tokens, tokenizer=tokenizer, diff_q_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec952cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the activations from disk.\n",
    "loaded_activations = MultiPromptActivations.load(data_activations_file)\n",
    "\n",
    "# Optional: verify the loaded activations match the saved ones.\n",
    "print(\"Loaded MultiPromptActivations object has:\", len(loaded_activations.prompts), \"prompts recorded.\")\n",
    "\n",
    "# Check again the activations\n",
    "loaded_activations.verify_recorded_activations(prompts=prompts, max_new_tokens=max_new_tokens, tokenizer=tokenizer, diff_q_size=True)\n",
    "\n",
    "print(\"Final MultiPromptActivations object has:\", len(loaded_activations.prompts), \"prompts recorded.\")\n",
    "\n",
    "# Extract the first prompt, first step, first layer, first head\n",
    "prompt_acts = loaded_activations.prompts[0]\n",
    "step_acts = prompt_acts.steps[0]\n",
    "layer_acts = step_acts.layers[0]\n",
    "attn = layer_acts.attention\n",
    "for head_idx, head_acts in attn.heads.items():\n",
    "    print(f\"Head {head_idx} activations:\")\n",
    "    print(head_acts.query.shape)\n",
    "    print(head_acts.attention_weights.shape)\n",
    "    print(head_acts.attention_outputs.shape)\n",
    "    print(head_acts.projected_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c19f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_acts = prompt_acts.steps[4]\n",
    "for layer_idx, layer_acts in step_acts.layers.items():\n",
    "    print(f\"Layer {layer_idx} activations:\")\n",
    "    moe_layer_acts = step_acts.layers[2].moe\n",
    "    for expert_id, expert_acts in moe_layer_acts.experts.items():\n",
    "        print(f\"Expert {expert_id} activations:\")\n",
    "        print(repr(expert_acts))\n",
    "        print(\"Gate value:\", expert_acts.gate_value)\n",
    "        print(\"MLP output:\", expert_acts.mlp_output)\n",
    "        print(\"Expert output:\", expert_acts.expert_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
